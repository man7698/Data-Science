# -*- coding: utf-8 -*-
"""Aula_10_Machine_Learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/storopoli/ciencia-de-dados/blob/master/notebooks/Aula_10_Machine_Learning.ipynb

[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/storopoli/ciencia-de-dados/master?filepath=notebooks%2FAula_10_Machine_Learning.ipynb)
<br>
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/storopoli/ciencia-de-dados/blob/master/notebooks/Aula_10_Machine_Learning.ipynb)

# *Machine Learning*

**Objetivos**: Aprender o que é *Machine Learning* e quais são os componentes de um algoritmo de ML.

## Defininição - *Machine Learning*

*Machine Learning* é uma área de estudo que fornece aos computadores a habilidade de aprender sem serem explicitamente programados.

> Um programa de computador que aprende a partir da experiência E em relação a algum tipo de tarefa T e alguma medida de desempenho P, se o seu desempenho em T, conforme medido por P, melhora com a experiência E.

Mitchell, T. M. (1997). Machine Learning. McGraw-Hill, New York.

### Experiência (E)

Em *Machine Learning* um programa de computador aprende sem ser explicitamente programado. Ele aprende a partir de um conjunto de dados que expressa toda *experiência* (E) que desejamos ensina-lo. Esse conjunto de dados é chamado de **conjunto de treinamento**. 

* **Aprendizagem Supervisionada**: o conjunto de treinamento é composto por amostras de entradas/saídas.
* **Aprendizagem Não-Supervisionada**:  conjunto de treinamento é composto por amostras de entradas apenas.
* ~~Aprendizagem por Reforço~~

### Tarefas (T)

* Classificação - Supervisionada qualitativa
* Regressão - Supervisionada quantitativa
* Agrupamento - Não-supervisionada

#### Tente responder: Classifique as sentenças a baixo como: Aprendizagem supervisionada (classifição ou regressão) ou não-supervisionada
* Estimar o preço de uma casa?
* Agrupar notícias semelhantes publicadas por várias fontes de informação?
* Identificar notícias que possuem maior engajamento de compartilhamentos em redes sociais?
* Determinar se uma pessoa tem câncer benigno ou maligno?
* Identificar padrões de navegação em sites?
* Determinar se um texto publicado em uma rede social é inadequado ou não?

### Desempenho (P)

Para medir o desempenho de um algoritmo de Machine Learning é preciso de uma medida de desempenho para mensurar a qualidade do processo de aprendizagem. Essa medida é conhecida como **função de custo** ou **função de erro**. Essa função é definida de acordo com o tipo de problema (aprendizagem supervisionada ou não-supervisionada). Essa função contém um **conjunto de parâmetros** a serem otimizada pelo um algoritmo de *Machine Learning*.

De maneira geral, pode-se dizer que o objetivo do algoritmo de *Machine Learning* é otimizar (aprender) o **conjunto de parâmetros** de tal forma que resultado da função seja o mínimo possível. Isso significa que algoritmo tem uma alta taxa de aprendizagem e uma baixa taxa de erro.

* Dividir os dados em
* Treino
* Teste
    * Aqui eu mensuro desempenho (P)

<img src="https://github.com/storopoli/ciencia-de-dados/blob/master/notebooks/images/train-test.png?raw=1" alt="train-test" style="width: 400px;"/>

### Exemplo: jogo de computador
- Tarefa $T$ é jogar xadrez. 
- Medida de desempenho $P$ é uma relação entre partidas ganhas contra oponentes versus perdidas. 
- Experiência $E$ é prática de partidas concluídas. Note que, estas experiências são descritas em um conjunto de dados chamado de **conjunto de treinamento**.

#### Tente responder: Classifique as sentenças a baixo como: Tarefa $T$, Experiências $E$ e Medida de desempenho $P$

- Classificar emails como spam ou não spam ?
- Verificar quais emails o algoritmo classifica como spam ?
- O número (ou fração) de emails corretamente classificados como spam ou não spam ?

## Generalização

A habilidade de desempenhar bem em dados não observados anteriormente.

Mensurada por erro:
* Dados de Treino: Erro de Treino
* Dados de Teste: Erro de Teste

### Erro do Algoritmo

2 Fatores:

1. Habilidade de Reduzir o Erro de Treino
2. Habilidade de Reduzir a Lacuna entre o Erro de Treino e o Erro de Teste

<img src="https://github.com/storopoli/ciencia-de-dados/blob/master/notebooks/images/train-vs-test-error.png?raw=1" alt="train-vs-test-error" style="width: 400px;"/>

<img src="https://github.com/storopoli/ciencia-de-dados/blob/master/notebooks/images/trainin4.gif?raw=1" alt="training" style="width: 500px;"/>

### *Overfitting* e *Underfitting*

* Centrais em *Machine Learning*
* Underfitting
    - Modelos **menos** flexíveis que o ideal
* Overfitting
    - Modelos **mais** flexíveis que o ideal   

<img src="https://github.com/storopoli/ciencia-de-dados/blob/master/notebooks/images/underfitting-overfitting-capacity.png?raw=1" alt="underfitting-overfitting-capacity" style="width: 500px;"/>

#### No Free Lunch Theorem (NFL)

> “Se você faz nenhum pressuposto dos dados, não há razão para preferir um modelo por outro”

> Wolpert, D. H. (1996). The Lack of a Priori Distinctions between Learning Algorithms. Neural Computation, 8(7), 1341–1390. https://doi.org/10.1162/neco.1996.8.7.1341
	
* Nenhum modelo é garantido que funcionará melhor
    * Ex: para alguns dados, regressão linear é melhor; para outros, redes neurais.
* A única maneira de saber é avaliar todos os modelos
* Por isso que não há *almoço grátis*

## Otimização

Método mais utilizado é o **Método do Gradiente** (*Gradient Descent*)

Inventado em 1847 por Augustin-Louis Cauchy. Usa a derivativa para minimizar uma função-alvo.

**Método iterativo**: a cada iteração, tenta ir para o local/global minima

<img src="https://github.com/storopoli/ciencia-de-dados/blob/master/notebooks/images/gradient-descent.png?raw=1" alt="gradient-descent" style="width: 400px;"/>

<img src="https://github.com/storopoli/ciencia-de-dados/blob/master/notebooks/images/gradient-descent.gif?raw=1" alt="gradient-descent-animation" style="width: 500px;"/>

<img src="https://github.com/storopoli/ciencia-de-dados/blob/master/notebooks/images/gradient-descent-2.gif?raw=1" alt="gradient-descent-animation" style="width: 500px;"/>

### Local/Global Minima/Maxima

<img src="https://github.com/storopoli/ciencia-de-dados/blob/master/notebooks/images/local-minima.png?raw=1" alt="local-minima" style="width: 400px;"/>

<img src="https://github.com/storopoli/ciencia-de-dados/blob/master/notebooks/images/gradient-descent-1.gif?raw=1" alt="gradient-descent-animation-2" style="width: 500px;"/>

<img src="https://github.com/storopoli/ciencia-de-dados/blob/master/notebooks/images/gradient-descent-3.gif?raw=1" alt="gradient-descent-animation-3" style="width: 500px;"/>

### Tipos de Método do Gradiente (*Gradient Descent*)

* *Batch Gradient Descent*: Dataset todo
* *Stochastic Gradient Descent*: Um exemplo aleatório do Dataset
* *Mini-batch Gradient Descent*: Amostras aleatórias do Dataset

<img src="https://github.com/storopoli/ciencia-de-dados/blob/master/notebooks/images/grad-descent-methods.png?raw=1" alt="grad-descent-methods" style="width: 500px;"/>

## Scikit-Learn

Você deve "treinar" o seu estimador do `sklearn` nos dados de treino e mensurar o desempenho nos dados de teste.

1. Instancia um objeto de um estimador do `sklearn`. Tradicionalmente regressores e classificadores ambos são instanciados como `clf`:
    ```python
    from sklearn.MODULO import ESTIMADOR
    clf = ESTIMADOR()
    ```
2. Treinar o estimador com os dados de treino usando o método `.fit()`:
    ```python
    clf.fit(X_train, y_train)
    ```
3. Mensurar o desempenho do estimador treinado nos dados de teste usando o método `.score()`:
    ```python
    clf.score(X_test, y_test)
    ```

### Como preparar um dataset do Pandas para um modelo de aprendizagem supervisionada do Scikit-Learn

Lembrando que o nosso dataset do pandas possui todos os atributos `X` (variáveis / *features*) que usaremos na estimação da resposta `y`.

* `X` são as variáveis **sem a resposta `y`**: `X = df.drop(['variavel_resposta'])`
* `y` é **apenas a variável resposta `y`**: `y = df['variavel_resposta']`

> Mas, professor... E os dados de **treino** e de **teste**?

O Scikit-Learn tem uma função que divide automaticamente de maneira aleatória em dados de **treino** e dados de **teste**. Esta função chama-se `train_test_split()`. Ela aceita uma matriz e retorna duas matrizes uma de treino e uma de teste. Além disso, pode-se especificar o tamanho da quebra em pontos percentuais (ex: `0.33` quebra o dataset em 67% treino e 33% teste). Para replicabilidade, pode-se especificar também uma *seed* do gerador de número aleatórios que aceita um número inteiro como *seed*.

> Obs: O `train_test_split()` aceita múltiplas matrices/tabelas para quebrar em treino/teste só tome cuidado com o tamanho da lista que a função retornará.

```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.33, random_state=42)
```

### Como *Treinar* um modelo de aprendizagem supervisionada no Scikit-Learn

Ao quebrar `X` e `y` em `X_train`, `X_test`, `y_train`, `y_test`, você obterá as seguintes variáveis:
* `X_train`: atributos dos meus dados de treino
* `y_train`: resposta dos meus dados de treino
* `X_teste`: atributos dos meus dados de teste
* `y_teste`: resposta dos meus dados de teste

```python
# Regressor
y_pred = clf.predict(X_test)
sklearn.metrics.r2_score(y_test, y_pred)
```
```python
# Classificador
y_pred = clf.predict(X_test)
sklearn.metrics.accuracy_score(y_test, y_pred)
```

```python
clf.score(X_test, y_test)
```

### Métricas de Desempenho Padrões do Scikit-Learn

* **Regressor**: $R^2$ do estimador - O quanto (em porcentagem) de variação da resposta `y` é "capturado" pelos atributos `X` do estimador - `Float` entre $0$ e $1$
* **Classificador**: Acurácia do estimador - O quanto (em porcentagem) o estimador acerta das classes da resposta `y` - `Float` entre $0$ e $1$

Estimador do Scikit-Learn: `clf`

* **Estimar** (Aprenda com os dados): `clf.fit(X, y)`
    * `X`: `DataFrame` Pandas ou `ndarray` NumPy (sem a variável que você quer prever - resposta) com linhas como observações e colunas como variáveis (atributos - *features*)
    * `y`: `Series` Pandas ou `ndarray` NumPy da variável de interesse resposta que deve ter o mesmo número observações que `X`
* **Métricas de Desempenho**: `clf.score(X, y)`
    * Classificação: Acurácia
    * Regressão: $R^2$ -  O quanto de variação da resposta que o seu estimador consegue "explicar"
* **Prever** uma resposta `y_new` a partir de **novos dados** `X_new` não-observados no treinamento: `y_new = clf.predict(X_new)`

## Atividade

1. Traga 2 exemplos de Tarefa Supervisionada
2. Traga 2 exemplos de Tarefa Não-Supervisionada
"""